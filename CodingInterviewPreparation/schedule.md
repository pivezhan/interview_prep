# NVIDIA Solutions Architect Interview - Complete Preparation Guide

 **Interview Date** : November 4, 2025

 **Preparation Period** : October 18 - November 3, 2025 (17 days)

 **Daily Time Allocation** : 4 hours interview prep + 2 hours MARL research

---

## üìä **Your Profile Analysis**

### **Strengths Matching Job Requirements**

‚úÖ **GPU-accelerated computing** - Jetson TX2/Orin NX experience

‚úÖ **Reinforcement Learning** - MARL frameworks, published at RTSS/RTCSA

‚úÖ **Energy/Performance optimization** - 34% performance improvement, 31.7% energy reduction

‚úÖ **Deep Learning frameworks** - PyTorch, TensorFlow, CUDA

‚úÖ **Academic collaboration** - Cross-institutional research partnerships

‚úÖ **Publications** - Top-tier venues (RTSS, RTCSA, ECRTS)

‚úÖ **U.S. Green Card holder** - No visa sponsorship needed

### **Areas to Strengthen**

‚ö†Ô∏è **NVIDIA Omniverse** - Digital twins, simulation platform

‚ö†Ô∏è **Isaac Sim/Isaac Lab** - Robotics simulation and RL

‚ö†Ô∏è **Generative AI at scale** - Foundation models, LLM deployment

‚ö†Ô∏è **Production DL optimization** - TensorRT, Triton Inference Server

‚ö†Ô∏è **Physical AI** - Sim-to-real transfer, robotics deployment

---

## üéØ **Interview Process Overview**

Based on NVIDIA Solutions Architect interviews:

1. **Recruiter Screen** (‚úÖ Completed - you have the interview!)
2. **Technical Screen** (75 minutes)
   * HackerRank coding challenge
   * 2-3 medium difficulty problems
   * Python or C++
3. **Virtual On-site** (3-4 hours)
   * Technical/Coding round (1-2 sessions)
   * Domain-specific system design
   * Behavioral with hiring manager
   * Team fit assessment

 **Common Question Themes** :

* Explain your research projects (STAR format)
* Optimize a deep learning model for deployment
* Debug GPU/training issues
* Design AI infrastructure for universities
* "Why NVIDIA?" and "Why Solutions Architect?"

---

## üìÖ **17-Day Detailed Preparation Schedule**

---

## **Phase 1: Foundations & Gap Filling (Days 1-6)**

---

### **Day 1 - Friday, October 18**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

* Your regular research work

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 3:00 PM: Self-Assessment & Job Analysis**

* [ ] Read job description line-by-line
* [ ] Create mapping document: JD requirement ‚Üí Your resume experience
* [ ] Prepare initial list of gaps
* [ ] **Resource** : [Job Description Analysis Template](https://nvidia.wd5.myworkdayjobs.com/NVIDIAExternalCareerSite/job/US-PA-Remote/Solutions-Architect--Higher-Education-and-Research_JR1999501?source=jobboardlinkedin)

**3:00 - 4:00 PM: Coding Warm-up**

* [X] Solve Problem #1: [Two Sum](https://leetcode.com/problems/two-sum/)
* [X] Solve Problem #2: [Longest Substring Without Repeating Characters](https://leetcode.com/problems/longest-substring-without-repeating-characters/)
* [ ] Focus on explaining your approach out loud

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 4:30 PM: Generative AI Refresher**

* [ ] Watch: [DeepLearning.AI - Generative AI Overview](https://www.youtube.com/@Deeplearningai)
* [ ] Review your certificate: "Generative AI with Large Language Models"

**4:30 - 5:30 PM: Isaac Sim Introduction**

* Read: [Isaac Sim Overview](https://docs.omniverse.nvidia.com/isaacsim/latest/overview.html)
* Watch: [What is NVIDIA Isaac Sim?](https://www.youtube.com/watch?v=9pdyNarvPLw)
* Take notes on key features for robotics

**5:30 - 6:00 PM: Resume Project Review**

* Review your RTSS 2024 paper
* Prepare 5-minute verbal summary
* Focus on: Problem ‚Üí Approach ‚Üí Results (34% improvement, 31.7% energy reduction)

 **üìù Evening Homework** : Write down 3 STAR stories from your resume

---

### **Day 2 - Saturday, October 19**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon: Extended 4-Hour Block (2:00 PM - 6:00 PM)**

**2:00 - 3:30 PM: Coding Practice**

* [X] Solve Problem #3: [Container With Most Water](https://leetcode.com/problems/container-with-most-water/)
* [X] Solve Problem #6: [Binary Tree Level Order Traversal](https://leetcode.com/problems/binary-tree-level-order-traversal/)
* [X] Solve Problem #9: [Course Schedule](https://leetcode.com/problems/course-schedule/) ‚≠ê (DAG - relevant to your work!)
* [X] **Resource** : [NeetCode YouTube Solutions](https://www.youtube.com/@NeetCode)

**3:30 - 4:30 PM: NVIDIA Omniverse Setup**

* [ ] Download: [NVIDIA Omniverse](https://www.nvidia.com/en-us/omniverse/download/)
* [ ] Install Isaac Sim
* [ ] **Guide** : [Isaac Sim Installation](https://docs.omniverse.nvidia.com/isaacsim/latest/installation/install_workstation.html)

**4:30 - 5:30 PM: PyTorch Practice - Problem #26**

* [X] **Task** : Implement a Multi-Layer Perceptron from scratch (no `nn.Sequential`)
* [X] **Reference** : [PyTorch nn.Module Tutorial](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)
* [X] **Code Template** :

```python
import torch
import torch.nn as nn

class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(MLP, self).__init__()
        # Your implementation here
  
    def forward(self, x):
        # Your implementation here
        pass
```

**5:30 - 6:00 PM: Review Your Jetson Code**

* Look at your TX2/Orin NX projects
* Prepare to discuss optimization techniques you used

 **üìù Evening Homework** : Set up Isaac Sim environment completely

---

### **Day 3 - Sunday, October 20**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 3:30 PM: Isaac Sim Hands-On Tutorial**

* [ ] Complete: [Isaac Sim Getting Started](https://docs.omniverse.nvidia.com/isaacsim/latest/introductory_tutorials/tutorial_intro_interface.html)
* [ ] Follow: [Isaac Sim Hello World](https://docs.omniverse.nvidia.com/isaacsim/latest/gui_tutorials/tutorial_gui_simple_robot.html)
* [ ] Take screenshots of your work

**3:30 - 4:00 PM: Coding - Problem #4**

* [X] Solve: [Product of Array Except Self](https://leetcode.com/problems/product-of-array-except-self/)
* [X] Practice explaining O(n) time, O(1) space solution

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: More Coding Practice**

* [X] Solve Problem #10: [Number of Islands](https://leetcode.com/problems/number-of-islands/)
* [X] Solve Problem #20: [Meeting Rooms II](https://www.lintcode.com/problem/919/) (or use [Interview Bit alternative](https://www.interviewbit.com/problems/meeting-rooms/))

**5:00 - 6:00 PM: Generative AI Deep Dive**

* [X] Read: [Transformers Explained](https://jalammar.github.io/illustrated-transformer/)
* [X] Watch: [Attention is All You Need Paper Explained](https://www.youtube.com/watch?v=iDulhoQ2pro)
* [X] Review diffusion models basics
* [ ] **Resource** : [Hugging Face Transformers Course](https://huggingface.co/learn/nlp-course/chapter1/1)

 **üìù Evening Homework** : Write STAR story #1 - "34% Performance Improvement Project"

---

### **Day 4 - Monday, October 21**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 3:30 PM: Isaac Lab Deep Dive**

* [ ] Read: [Isaac Lab Documentation](https://isaac-sim.github.io/IsaacLab/)
* [ ] Clone repo: `git clone https://github.com/isaac-sim/IsaacLab.git`
* [ ] Follow: [Isaac Lab Installation Guide](https://isaac-sim.github.io/IsaacLab/source/setup/installation.html)
* [ ] Run basic example

**3:30 - 4:00 PM: Coding - Problem #7**

* [X] Solve: [Validate Binary Search Tree](https://leetcode.com/problems/validate-binary-search-tree/)

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: More Coding**

* [X] Solve Problem #15: [Longest Increasing Subsequence](https://leetcode.com/problems/longest-increasing-subsequence/)
* [X] Solve Problem #24: [Maximum Subarray](https://leetcode.com/problems/maximum-subarray/)
* [X] For #24, discuss how parallel reduction would work on GPU

**5:00 - 6:00 PM: PyTorch Training Loop - Problem #27**

* [X] **Task** : Write complete training loop with proper device handling
* [ ] **Reference** : [PyTorch Training Tutorial](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)
* [ ] **Must Include** : `.to(device)`, loss computation, `backward()`, `optimizer.step()`, `zero_grad()`
* [ ] **Code Template** :

```python
def train_one_epoch(model, dataloader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
  
    for batch_idx, (inputs, targets) in enumerate(dataloader):
        # Your implementation here
        pass
  
    return running_loss / len(dataloader)
```

 **üìù Evening Homework** : Review your RTCSA 2025 paper on statistical learning

---

### **Day 5 - Tuesday, October 22**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 3:00 PM: NVIDIA NeMo Framework**

* [ ] Read: [NVIDIA NeMo Overview](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html)
* [ ] Watch: [NeMo Framework Introduction](https://www.youtube.com/watch?v=vMG3JVN73ZU)
* [ ] Understand: How NeMo helps with LLM training/deployment

**3:00 - 4:00 PM: Coding Practice**

* [X] Solve Problem #11: [Clone Graph](https://leetcode.com/problems/clone-graph/)
* [X] Solve Problem #16: [Coin Change](https://leetcode.com/problems/coin-change/)

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: Problem #18**

* [X] Solve: [LRU Cache](https://leetcode.com/problems/lru-cache/)
* [ ] This tests system design coding skills

**5:00 - 6:00 PM: GPU Optimization - Problems #21 & #22**

**Problem #21: Matrix Multiplication**

* [X] Implement in C++: naive O(n¬≥) version
* [X] Implement: cache-optimized version with loop tiling
* [X] **Reference** : [Cache-Friendly Code](https://www.geeksforgeeks.org/cache-memory-in-computer-organization/)

**Problem #22: CUDA Debugging**

* [X] Browse: [NVIDIA CUDA Samples - Reduction](https://github.com/NVIDIA/cuda-samples/tree/master/Samples/2_Concepts_and_Techniques/reduction)
* [X] Study shared memory race conditions
* [X] **Reference** : [CUDA Programming Guide - Shared Memory](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory)

 **üìù Evening Homework** : Write STAR story #2 - "Cross-Institutional Collaboration"

---

### **Day 6 - Wednesday, October 23**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 3:15 PM: Mock Coding Challenge #1**

* [ ] **Platform** : [LeetCode Mock Assessment](https://leetcode.com/assessment/)
* [ ] Set timer for 75 minutes
* [ ] Solve 2 medium problems
* [ ] Simulate real interview conditions

**3:15 - 4:00 PM: Review & Analysis**

* [ ] Analyze mistakes
* [ ] Optimize solutions
* [ ] Practice explaining approach out loud

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: Behavioral Prep - STAR Story Development**

**Story #1: 34% Performance Improvement (Wayne State)**

* [ ] **Situation** : Researchers struggling with OpenMP DAG workloads on Jetson TX2, high energy, thermal throttling
* [ ] **Task** : Develop energy-aware scheduler
* [ ] **Action** : Built HMARL framework with DVFS optimization, published at RTSS 2025
* [ ] **Result** : 34% performance improvement, 31.7% energy reduction

**Write out full story in 2-3 minutes speaking time**

**5:00 - 6:00 PM: Prepare Behavioral Questions**

* [ ] Read: [NVIDIA Interview Questions - Glassdoor](https://www.glassdoor.com/Interview/NVIDIA-Solutions-Architect-Interview-Questions-EI_IE7633.0,6_KO7,26.htm)
* [ ] Prepare answers for:
  * [ ] "Tell me about yourself"
  * [ ] "Why NVIDIA?"
  * [ ] "Why Solutions Architect role?"
  * [ ] "Describe a technical challenge you overcame"

 **üìù Evening Homework** : Practice STAR story #1 out loud 3 times

---

## **Phase 2: Domain Mastery & NVIDIA Ecosystem (Days 7-12)**

---

### **Day 7 - Thursday, October 24**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 4:00 PM: Isaac Lab Hands-On - Connect to Your Research**

* [ ] **Project** : Build simple RL environment in Isaac Lab
* [ ] **Goal** : Create 2-agent cooperative task (tie to your MARL work)
* [ ] **Tutorial** : [Isaac Lab RL Environment Tutorial](https://isaac-sim.github.io/IsaacLab/source/tutorials/03_envs/create_rl_env.html)
* [ ] **Extension** : Think about how this could apply to DVFS optimization scenario

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: Coding Practice**

* [ ] Solve Problem #8: [Lowest Common Ancestor](https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree/)
* [ ] Solve Problem #12: [Word Ladder](https://leetcode.com/problems/word-ladder/)

**5:00 - 5:30 PM: Problem #17**

* Solve: [Edit Distance](https://leetcode.com/problems/edit-distance/)
* Classic DP optimization problem

**5:30 - 6:00 PM: Multi-GPU Training Concepts**

* Read: [PyTorch Distributed Overview](https://pytorch.org/tutorials/beginner/dist_overview.html)
* Study: Data parallelism vs Model parallelism
* Learn about: [NVIDIA NCCL](https://developer.nvidia.com/nccl)
* Watch: [Distributed Training Explained](https://www.youtube.com/watch?v=VEbPJHlxOPQ)

 **üìù Evening Homework** : Document your Isaac Lab project with screenshots

---

### **Day 8 - Friday, October 25**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 4:00 PM: Deep Learning Implementation Practice**

**Problem #28: Data Parallel Multi-GPU (1 hour)**

* Wrap a model using `nn.DataParallel()` or `DistributedDataParallel`
* **Reference** : [PyTorch Multi-GPU Training](https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html)
* **Code** :

```python
model = MyModel()
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)
model.to(device)
```

**Problem #29: Debug Non-Learning Model (1 hour)**

* **Scenario** : Given a model with stagnant loss, create debugging checklist
* **Common Issues to Check** :
* Learning rate (too high/low)
* Gradient flow (vanishing/exploding)
* Data normalization
* Label correctness
* Loss function choice
* **Reference** : [Andrej Karpathy - Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: GTC Talks on Physical AI**

* Watch: [GTC 2024 - Physical AI Keynote](https://www.nvidia.com/gtc/)
* Search for: "Physical AI" and "Robotics" sessions
* Take notes on NVIDIA's vision for Physical AI
* **Alternative** : [NVIDIA Blog - Physical AI](https://blogs.nvidia.com/blog/what-is-physical-ai/)

**5:00 - 6:00 PM: Coding Practice**

* Solve Problem #5: [Sliding Window Maximum](https://leetcode.com/problems/sliding-window-maximum/)
* Solve Problem #13: [Serialize and Deserialize Binary Tree](https://leetcode.com/problems/serialize-and-deserialize-binary-tree/)

 **üìù Evening Homework** : Write STAR story #3 - "Moffett Internship Collaboration"

---

### **Day 9 - Saturday, October 26**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon: Extended Session (2:00 PM - 6:00 PM)**

**2:00 - 3:00 PM: NVIDIA Omniverse Deep Dive**

* Read: [Omniverse Platform Overview](https://docs.omniverse.nvidia.com/platform/latest/index.html)
* Understand: Digital twins concept
* Watch: [Omniverse for Robotics](https://www.youtube.com/results?search_query=nvidia+omniverse+robotics)
* Learn: How researchers use Omniverse for simulation

**3:00 - 5:00 PM: Advanced PyTorch - Problems #30, #31, #32, #33**

**Problem #30: Attention Mechanism (45 min)**

```python
import torch
import torch.nn.functional as F

def scaled_dot_product_attention(Q, K, V, mask=None):
    """
    Q: (batch, seq_len, d_k)
    K: (batch, seq_len, d_k)
    V: (batch, seq_len, d_v)
    """
    # Your implementation here
    # Hint: scores = Q @ K.T / sqrt(d_k)
    # Apply softmax, then multiply by V
    pass
```

* **Reference** : [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)

**Problem #31: Custom Dataset (30 min)**

* Create PyTorch Dataset class with image augmentation
* **Reference** : [PyTorch Custom Dataset Tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)

**Problem #32: Model Profiling (30 min)**

* Use `torch.profiler` to profile a simple CNN
* **Reference** : [PyTorch Profiler Tutorial](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)

**Problem #33: Gradient Clipping & LR Scheduling (15 min)**

* Add to training loop from Day 4
* **Reference** : [PyTorch Optimization Docs](https://pytorch.org/docs/stable/optim.html)

**5:00 - 6:00 PM: Solutions Architect Scenarios Practice**

**Scenario #41: Slow PyTorch Training**

* Write debugging checklist:
  1. Check GPU utilization: `nvidia-smi dmon`
  2. Profile with `torch.profiler`
  3. Check data loading: CPU vs GPU time
  4. Verify batch size optimization
  5. Test mixed precision training (AMP)
  6. Check for CPU-GPU transfer bottlenecks

**Scenario #42: GenAI Inference Pipeline**

* Sketch architecture for university HPC deployment
* Consider: TensorRT optimization, Triton Inference Server
* **Reference** : [NVIDIA Triton](https://github.com/triton-inference-server/server)

**Scenario #43: Sim-to-Real Transfer**

* List key challenges: domain gap, sensor noise, dynamics mismatch
* Solutions: domain randomization, fine-tuning, model compression

 **üìù Evening Homework** : Create one-page cheat sheet of PyTorch optimization techniques

---

### **Day 10 - Sunday, October 27**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 4:00 PM: Reinforcement Learning Implementation - Problems #34-37**

**Problem #34: Q-Learning GridWorld (45 min)**

```python
import numpy as np

class GridWorld:
    def __init__(self, size=5):
        self.size = size
        self.q_table = np.zeros((size, size, 4))  # 4 actions: up, down, left, right
  
    def q_learning(self, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):
        # Your implementation here
        pass
```

* **Reference** : [Sutton &amp; Barto RL Book - Chapter 6](http://incompleteideas.net/book/RLbook2020.pdf)

**Problem #35: Epsilon-Greedy (15 min)**

```python
def epsilon_greedy(Q, state, epsilon, decay=0.995):
    if np.random.random() < epsilon:
        return np.random.randint(4)  # Random action
    else:
        return np.argmax(Q[state])  # Greedy action
```

**Problem #36: Experience Replay Buffer (30 min)**

```python
from collections import deque
import random

class ReplayBuffer:
    def __init__(self, capacity=10000):
        self.buffer = deque(maxlen=capacity)
  
    def add(self, state, action, reward, next_state, done):
        # Your implementation
        pass
  
    def sample(self, batch_size):
        # Your implementation
        pass
```

* **Reference** : [DQN Paper](https://arxiv.org/pdf/1312.5602.pdf)

**Problem #37: Simple MARL Environment (30 min)**

* Create 2-agent cooperative environment
* **Connect to your work** : Think about how agents could cooperate on DVFS decisions

```python
class MAEnv:
    def __init__(self, n_agents=2):
        self.n_agents = n_agents
  
    def step(self, actions):
        # Joint action, shared reward
        pass
```

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: Review Your Published Papers**

* RTSS 2025 (submitted): HMARL for OpenMP DAG
* RTCSA 2025: Statistical learning for task allocation
* ECRTS 2023: Precise DAG scheduling with DPM
* **Practice** : Explain each in 3 minutes to a non-expert

**5:00 - 5:30 PM: Prepare Behavioral STAR Story #4**
**Story: Collaboration with Different Disciplines**

* Use your cross-institutional research teams
* Highlight communication with researchers from different backgrounds

**5:30 - 6:00 PM: Research Pittsburgh Ecosystem**

* Read about: [CMU Robotics Institute](https://www.ri.cmu.edu/)
* Read about: [University of Pittsburgh CSAI](https://www.csai.pitt.edu/)
* Understand: [NVIDIA AI Technology Center (NVAITC)](https://www.nvidia.com/en-us/industries/higher-education-research/ai-technology-centers/)

 **üìù Evening Homework** : List 3 potential research collaborations you could support in Pittsburgh

---

### **Day 11 - Monday, October 28**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 4:00 PM: System Design Practice - Scenarios #44, #45, #46**

**Scenario #44: Budget-Constrained Foundation Model Training (45 min)**

* Design solution for university with limited GPU budget
* **Techniques to discuss** :
* Mixed precision (FP16/BF16)
* Gradient checkpointing
* Parameter-efficient fine-tuning (LoRA, QLoRA)
* Flash Attention
* Efficient optimizers (AdamW with fused kernels)
* **Reference** : [Hugging Face - Efficient Training](https://huggingface.co/docs/transformers/perf_train_gpu_one)

**Scenario #45: Energy Spike Debugging (45 min)** ‚≠ê **YOUR SPECIALTY!**

* Create debugging workflow for heterogeneous AI workload
* **Your expertise** : DVFS states, thermal throttling, task migration
* Draw system diagram showing monitoring points
* **Reference** : Your RTSS/RTCSA papers, `perf`, `powertop` tools

**Scenario #46: Robot Training Pipeline with Isaac Lab (30 min)**

* Design end-to-end pipeline: synthetic data ‚Üí training ‚Üí sim-to-real
* Include: domain randomization, real-world augmentation
* **Reference** : [Isaac Lab Workflows](https://isaac-sim.github.io/IsaacLab/source/overview/workflows.html)

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: DL Training at Scale - Deep Dive**

* Study: [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) for model parallelism
* Understand: Pipeline parallelism, tensor parallelism
* Read: [Efficient Large-Scale Training](https://arxiv.org/abs/2104.04473)
* Watch: [NVIDIA - Scaling LLM Training](https://www.youtube.com/results?search_query=nvidia+scaling+llm+training)

**5:00 - 6:00 PM: Coding Practice**

* Solve Problem #23: **PyTorch DataLoader Optimization** (Custom)
  * Create scenario where training is slow
  * Identify bottleneck: `num_workers`, `pin_memory`, prefetch_factor
  * **Reference** : [PyTorch Performance Tuning](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)
* Solve Problem #25: **Energy Consumption Calculator** (Custom)
  * Write Python function: given frequency schedule + task durations ‚Üí energy
  * Use formula: Power = Œ± √ó f¬≥
* Solve Problem #38: [Logger Rate Limiter](https://leetcode.com/problems/logger-rate-limiter/)

 **üìù Evening Homework** : Create system design template with standard components (load balancer, cache, storage, compute)

---

### **Day 12 - Tuesday, October 29**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 4:00 PM: Mock Technical Interview #1**

* **Platform** : [Pramp](https://www.pramp.com/) or find a peer
* **Format** :
* 5 min: Introductions
* 45 min: Coding problem (medium difficulty)
* 30 min: Domain questions (explain your research, optimize a DL model)
* 10 min: Your questions
* **Record session** if possible for review

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: Review Mock Interview**

* Identify weak areas
* Practice clearer explanations
* Optimize coding approach

**5:00 - 5:30 PM: Coding - Problems #39, #40**

**Problem #39: Job Scheduler with Priorities** (Custom)

* Implement using heap/priority queue
* Add resource constraints
* **Similar to** : [LeetCode #1834 - Single-Threaded CPU](https://leetcode.com/problems/single-threaded-cpu/)
* **Extension** : Add energy budget constraint (tie to your work!)

**Problem #40: GPU Utilization Monitor** (Custom)

```python
import pynvml

pynvml.nvmlInit()
handle = pynvml.nvmlDeviceGetHandleByIndex(0)

def monitor_gpu(threshold=90):
    info = pynvml.nvmlDeviceGetUtilizationRates(handle)
    if info.gpu > threshold:
        print(f"Alert: GPU utilization {info.gpu}%")
    return info.gpu
```

* **Reference** : [NVIDIA Management Library (NVML)](https://developer.nvidia.com/nvidia-management-library-nvml)

**5:30 - 6:00 PM: Pittsburgh Ecosystem Deep Dive**

* Read about NVAITC Pittsburgh initiatives
* Research: CMU's AI research labs, Pitt's medical AI work
* Prepare talking points about supporting local researchers

 **üìù Evening Homework** : Prepare 5 thoughtful questions for your interviewer

---

## **Phase 3: Integration & Polish (Days 13-17)**

---

### **Day 13 - Wednesday, October 30**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 4:00 PM: Technical Presentation Preparation**

**Presentation #1: HMARL DVFS Framework (10 minutes)**

* **Slide 1** : Problem statement (energy/thermal challenges on Jetson)
* **Slide 2** : Your approach (HMARL, DVFS optimization)
* **Slide 3** : Architecture diagram
* **Slide 4** : Results (34% perf, 31.7% energy)
* **Slide 5** : Impact & future work

 **Practice** : Record yourself, aim for 8-10 minutes

* Explain like you're presenting to a university dean (non-technical)
* Then explain to a technical researcher

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:30 PM: Solutions Architect Scenarios #47, #48, #49, #50**

**Scenario #47: Multi-Node Distributed Training (30 min)**

* Design distributed training across 4 DGX nodes
* **Architecture Components** :
* Data parallelism strategy
* NCCL for all-reduce operations
* Gradient synchronization approach
* Fault tolerance (checkpointing)
* **Draw diagram** showing: nodes, GPUs per node, communication patterns
* **Reference** : [NVIDIA Deep Learning Examples](https://github.com/NVIDIA/DeepLearningExamples)

**Scenario #48: GPU Crash Troubleshooting (20 min)**

* **Common Issues Checklist** :

1. CUDA Out of Memory ‚Üí reduce batch size, gradient checkpointing
2. Data type mismatches ‚Üí ensure float32/float16 consistency
3. Device placement ‚Üí check `.to(device)` for all tensors
4. CUDA version incompatibility ‚Üí verify CUDA/PyTorch versions
5. Invalid tensor operations ‚Üí add assertions for tensor shapes

* **Reference** : [PyTorch CUDA Semantics](https://pytorch.org/docs/stable/notes/cuda.html)

**Scenario #49: Jetson Thermal Management** (20 min) ‚≠ê **YOUR EXPERTISE!**

* Design thermal management system for edge AI deployment
* **Components** :
* Temperature monitoring (thermal zones)
* Dynamic frequency/voltage scaling
* Workload throttling strategies
* Active cooling integration
* **Connect to your research** : Your DVFS work directly applies!
* **Reference** : [Jetson Power Management](https://docs.nvidia.com/jetson/archives/r35.1/DeveloperGuide/text/SD/PlatformPowerAndPerformance.html)

**Scenario #50: University AI Platform (20 min)**

* Design campus-wide AI research infrastructure
* **Hardware Layer** : DGX clusters (training), Jetson devices (edge), workstations
* **Software Stack** : CUDA, cuDNN, TensorRT, Triton Inference Server
* **Platforms** : Omniverse (digital twins), Isaac (robotics), NeMo (LLMs)
* **Management** : Resource scheduling, user authentication, cost tracking
* **Reference** : [NVIDIA AI Enterprise](https://www.nvidia.com/en-us/data-center/products/ai-enterprise/)

**5:30 - 6:00 PM: Prepare Behavioral STAR Story #5**
**Story: Overcoming Technical Challenge**

* Use: Debugging energy spikes or optimizing MARL framework
* Emphasize: Problem-solving methodology, persistence, results

 **üìù Evening Homework** : Practice all 5 STAR stories out loud, time yourself

---

### **Day 14 - Thursday, October 31**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 4:00 PM: Mock Interview #2 - Full Panel Simulation**

**Format** (simulate full on-site):

* **Round 1 (45 min)** : Behavioral interview
* Tell me about yourself (3 min)
* Why NVIDIA? (2 min)
* Why Solutions Architect? (2 min)
* STAR story #1 (4 min)
* STAR story #2 (4 min)
* "Tell me about a time you failed" (4 min)
* "Describe working with difficult stakeholder" (4 min)
* Your questions (5 min)
* **Round 2 (45 min)** : System design
* Design AI inference system for university research lab
* Include: hardware selection, optimization, scaling, monitoring
* Draw architecture diagram
* **Round 3 (30 min)** : Technical depth
* Explain your MARL research in detail
* How would you optimize it further?
* Questions about RL concepts

 **Platform** : [Interviewing.io](https://interviewing.io/) or peer mock

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: Prepare "Why NVIDIA?" Answer**

 **Structure** :

1. **Personal Connection** (30 sec)
   * "I've used NVIDIA Jetson TX2 and Orin NX extensively in my PhD research"
   * "Your GPUs enabled my 34% performance improvement on embedded AI"
2. **Alignment with Mission** (30 sec)
   * "I'm passionate about democratizing AI for researchers"
   * "NVAITC's model of academic collaboration resonates with my cross-institutional work"
3. **Role-Specific Fit** (30 sec)
   * "Solutions Architect combines my technical depth with desire to help others succeed"
   * "Supporting Pittsburgh's research ecosystem‚ÄîCMU, Pitt‚Äîexcites me"
4. **Future Impact** (30 sec)
   * "I want to help researchers optimize AI workloads for energy efficiency"
   * "Enable next generation of Physical AI and robotics research"

 **Practice** : Record and refine to 2 minutes

**5:00 - 5:30 PM: Prepare Your Questions for Interviewer**

 **Technical Questions** :

1. "What are the most common technical challenges researchers face when adopting NVIDIA platforms?"
2. "How does the Solutions Architect team collaborate with NVIDIA product/engineering teams to provide feedback?"
3. "Can you describe a recent project where NVAITC Pittsburgh made significant impact?"

 **Role Questions** :
4. "What does success look like for this role in the first 6-12 months?"
5. "How is the team structured? Who would I collaborate with most closely?"
6. "What opportunities exist for professional development and learning new NVIDIA technologies?"

 **Culture Questions** :
7. "How does NVIDIA support work-life balance, especially with the travel requirements?"
8. "What do you enjoy most about working as a Solutions Architect at NVIDIA?"

**5:30 - 6:00 PM: Review Mock Interview Performance**

* Watch recording (if available)
* Identify areas to improve:
  * Speaking pace (not too fast)
  * Clarity of explanations
  * Confidence level
  * Body language (on video)

 **üìù Evening Homework** : Write thank-you email template (to customize post-interview)

---

### **Day 15 - Friday, November 1**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)**

#### **Afternoon Session 1 (2:00 PM - 4:00 PM)**

**2:00 - 3:30 PM: Light Coding Review - Revisit Weak Problems**

* Go back to 5 problems you struggled with most
* Re-solve from scratch
* Focus on explaining your approach clearly
* **Suggested review** :
* If you struggled with DP: re-do problems #14, #15, #16, #17
* If you struggled with graphs: re-do problems #9, #10, #11, #12
* Practice talking through solution before coding

**3:30 - 4:00 PM: LeetCode Easy Problems for Confidence**

* [Two Pointers: Valid Palindrome](https://leetcode.com/problems/valid-palindrome/)
* [Stack: Valid Parentheses](https://leetcode.com/problems/valid-parentheses/)
* [Array: Best Time to Buy and Sell Stock](https://leetcode.com/problems/best-time-to-buy-and-sell-stock/)

#### **Afternoon Session 2 (4:00 PM - 6:00 PM)**

**4:00 - 5:00 PM: Final NVIDIA Tech Review**

 **Isaac Sim/Lab Key Features** :

* Physics simulation for robotics
* Synthetic data generation
* ROS/ROS2 integration
* RL training with Isaac Gym
* **Your talking point** : "Excited to learn how Isaac Lab could accelerate robotics research I could support"

 **Omniverse Key Features** :

* USD (Universal Scene Description) foundation
* Real-time collaboration
* Digital twin creation
* Integration with CAD, rendering, simulation tools
* **Your talking point** : "See potential for universities to build digital twins of campus infrastructure for research"

 **NeMo Framework Key Features** :

* LLM training and customization
* Automatic mixed precision
* Multi-GPU/multi-node scaling
* Model parallel strategies
* **Your talking point** : "Could help researchers fine-tune foundation models efficiently on limited budgets"

**5:00 - 6:00 PM: Presentation #2 Preparation**
**Flow-Matching & Few-Shot Learning for Physical AI (10 minutes)**

* **Slide 1** : What is Physical AI? (real-time data from physical sensors)
* **Slide 2** : Your approach (flow-matching, few-shot learning pipelines)
* **Slide 3** : Integration with heterogeneous devices
* **Slide 4** : Applications to robotics and edge AI
* **Slide 5** : How this connects to NVIDIA ecosystem (Isaac, Jetson)

 **Practice** : Present to someone non-technical, then technical

 **üìù Evening Homework** : Relax! Watch a movie, exercise, prepare healthy meals for weekend

---

### **Day 16 - Saturday, November 2**

#### **Morning: MARL Research (9:00 AM - 11:00 AM)** - Light work today!

#### **Afternoon: Light Review Only (2:00 PM - 4:00 PM)**

**2:00 - 3:00 PM: STAR Stories Final Practice**

* Practice all 5 stories out loud
* Time each one (aim for 3-4 minutes)
* Record final versions
* **Stories to review** :

1. 34% Performance Improvement (Wayne State)
2. Cross-Institutional Collaboration
3. Moffett Internship - Interdisciplinary Team
4. Working with Different Disciplines
5. Overcoming Technical Challenge

**3:00 - 3:30 PM: Resume Walk-through**

* Read your resume top to bottom
* Be ready to explain every single bullet point
* Practice transitions between roles
* No detail memorization‚Äîjust natural familiarity

**3:30 - 4:00 PM: Relaxation & Confidence Building**

* Light stretching or yoga
* Visualization: imagine interview going well
* Positive affirmations about your qualifications
* Review your strengths list from Day 1

**Evening: Free Time**

* Early dinner (not too heavy)
* Avoid caffeine after 6 PM
* Prepare clothes for interview
* No studying after 8 PM
* **Goal** : In bed by 10 PM for 8+ hours sleep

 **üìù Evening Homework** : None! Rest and recharge.

---

### **Day 17 - Sunday, November 3**

#### **Morning: Light MARL Research (9:00 AM - 11:00 AM)** - Give yourself a break!

#### **Afternoon: Very Light Review (2:00 PM - 4:00 PM)**

**2:00 - 2:30 PM: Technical Cheat Sheet Review**

 **CUDA Basics** :

* Grid ‚Üí Blocks ‚Üí Threads
* Shared memory vs global memory
* `__syncthreads()` for synchronization
* Memory coalescing for performance

 **PyTorch Quick Reference** :

```python
# Model to GPU
model.to(device)

# Training step
optimizer.zero_grad()
loss = criterion(output, target)
loss.backward()
optimizer.step()

# Mixed precision
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
with autocast():
    output = model(input)
```

 **NVIDIA Products One-Liner Each** :

* **Isaac Sim** : Physics-accurate robot simulation
* **Isaac Lab** : RL training framework for robotics
* **Omniverse** : Collaborative 3D design and digital twin platform
* **NeMo** : Framework for building and customizing LLMs
* **TensorRT** : Inference optimization engine
* **Triton** : Model serving and inference platform
* **NCCL** : Multi-GPU communication library

**2:30 - 3:00 PM: One Practice Problem (Easy - Confidence Booster)**

* [Merge Two Sorted Lists](https://leetcode.com/problems/merge-two-sorted-lists/)
* Focus on clear explanation, not speed
* **Don't time yourself** - just enjoy solving it

**3:00 - 3:30 PM: Interview Logistics Preparation**

 **Technical Setup** :

* Test Zoom/video platform (camera, microphone, speakers)
* Ensure stable internet connection (close other apps)
* Charge laptop fully, have charger nearby
* Test screen sharing if needed
* Have backup device ready (phone with Zoom)

 **Physical Setup** :

* Clean, professional background
* Good lighting (face should be well-lit)
* Quiet room (inform family/roommates)
* Glass of water nearby
* Notebook and pen for notes
* Copy of your resume printed

 **Digital Setup** :

* Have these open in browser tabs:
  * Your resume (PDF)
  * Job description
  * NVIDIA website
  * Your prepared questions
* CoderPad or similar if coding round mentioned

**3:30 - 4:00 PM: Final Mental Preparation**

* Review "Why NVIDIA?" answer one last time
* Review your questions for interviewer
* Quick meditation or breathing exercises
* Remind yourself: **You are qualified for this role**

 **Evening Schedule** :

* **4:00 PM** : Done with prep! Close all study materials
* **5:00 PM** : Light exercise (walk, yoga)
* **6:00 PM** : Healthy dinner
* **7:00 PM** : Relaxing activity (read fiction, watch comedy)
* **8:00 PM** : Prepare tomorrow's outfit (business casual)
* **9:00 PM** : Light evening routine
* **9:30 PM** : In bed, no screens
* **10:00 PM** : Asleep (target 8 hours sleep)

 **üìù Evening Homework** : NONE. Sleep is your homework!

---

## **Interview Day - Monday, November 4, 2025** üéØ

### **Morning Routine**

 **7:00 AM** : Wake up naturally (no harsh alarm)

* Light stretching
* Shower
* Professional attire (even for video interview)

 **7:30 AM** : Healthy breakfast

* Complex carbs + protein
* Avoid too much caffeine
* Stay hydrated

 **8:00 AM** : Light warm-up (if interview is later)

* Read one article from [NVIDIA Blog](https://blogs.nvidia.com/)
* Review your "Why NVIDIA?" answer
* **Do NOT cram or study new material**

 **30 Minutes Before Interview** :

* Use bathroom
* Set phone to Do Not Disturb
* Close all unnecessary browser tabs
* Have only: video platform, resume, job description, questions open
* Breathing exercises: 4-7-8 technique (breathe in 4 sec, hold 7 sec, exhale 8 sec)

 **10 Minutes Before** :

* Join meeting (be early, wait in lobby)
* Final tech check
* Smile (even before they join - sets positive mood)
* Positive self-talk: "I'm prepared. I'm qualified. I'll do great."

---

### **During the Interview**

#### **Opening (First 5 minutes)**

* **Smile and make eye contact** (look at camera, not screen)
* **"Tell me about yourself"** - Use your prepared 2-3 minute pitch:
  * PhD candidate in Computer Science at Wayne State
  * Specializing in GPU-accelerated RL and energy optimization
  * Published at RTSS, RTCSA, ECRTS
  * Hands-on NVIDIA Jetson experience
  * Passionate about supporting research community
  * Excited about Solutions Architect role at NVIDIA

#### **Coding Round** (if applicable)

 **Strategy** :

1. **Clarify the problem** (2-3 min)
   * Restate problem in your own words
   * Ask about input constraints
   * Clarify expected output format
   * Ask about edge cases
2. **Plan your approach** (3-5 min)
   * Think out loud
   * Discuss trade-offs
   * Get interviewer buy-in before coding
   * "I'm thinking of using [algorithm] because..."
3. **Code** (20-30 min)
   * Write clean, readable code
   * Use meaningful variable names
   * Add comments for complex logic
   * Test as you go
4. **Test & optimize** (5-10 min)
   * Walk through example inputs
   * Check edge cases
   * Discuss time/space complexity
   * Suggest optimizations

 **If stuck** :

* "Let me think about this for a moment..."
* Ask for hints: "Would it help to consider..."
* Don't panic - talk through your thought process

#### **Technical/Domain Questions**

 **When explaining your research** :

* Use the "explain to my grandmother" test
* Start high-level, then drill down
* Use analogies where appropriate
* Show enthusiasm for your work
* Connect to how it helps researchers

 **Sample responses** :

 *"Explain your HMARL framework"* :

* "Imagine you have multiple workers (agents) who need to coordinate to complete tasks efficiently while staying within an energy budget. My framework uses reinforcement learning so these agents learn to cooperate‚Äîsome might decide to slow down to save energy while others speed up to meet deadlines. The result was 34% better performance and 31.7% energy savings on NVIDIA Jetson boards."

 *"How would you optimize a slow-training model?"* :

* "I'd start with profiling to identify bottlenecks‚Äîis it data loading, GPU utilization, or the model itself? Tools like nvidia-smi and torch.profiler help here. Common fixes include: increasing num_workers for data loading, enabling mixed precision training, optimizing batch size, and checking for CPU-GPU transfer bottlenecks. In my research, I've used similar methodologies to achieve significant performance gains."

 *"What's your experience with NVIDIA platforms?"* :

* "I've worked extensively with Jetson TX2 and Orin NX for my energy-aware RL research. I've optimized AI workloads on these heterogeneous platforms, dealing with thermal constraints and DVFS. I'm excited to learn more about your newer platforms like Isaac Sim for robotics research and how I can help researchers leverage them effectively."

#### **Behavioral Questions**

 **Use STAR format** :

* **Situation** : Set context briefly (1 min)
* **Task** : What needed to be done (30 sec)
* **Action** : What YOU did specifically (1-2 min)
* **Result** : Quantifiable outcomes (30 sec)

 **Tips** :

* Focus on YOUR actions (use "I" not "we")
* Be specific, not generic
* Include metrics when possible
* Show learning/growth
* Stay positive (even for "failure" questions)

 **Common questions prepared** :

* ‚úÖ Tell me about yourself
* ‚úÖ Why NVIDIA?
* ‚úÖ Why Solutions Architect?
* ‚úÖ Describe a technical challenge
* ‚úÖ Tell me about a collaboration
* ‚úÖ Describe a failure/learning experience
* ‚úÖ How do you stay current with AI/ML?
* ‚úÖ Describe working with difficult stakeholder

#### **System Design/Architecture Round**

 **Approach** :

1. **Clarify requirements** (5 min)
   * Functional requirements
   * Scale (users, data, throughput)
   * Performance requirements
   * Budget constraints
2. **High-level design** (10 min)
   * Draw major components
   * Explain data flow
   * Discuss technology choices
3. **Deep dive** (15 min)
   * Pick 2-3 components to detail
   * Discuss trade-offs
   * Mention NVIDIA solutions where relevant
4. **Optimizations** (5 min)
   * Performance optimizations
   * Cost optimizations
   * Scalability considerations

 **Connect to NVIDIA** :

* "For GPU acceleration, I'd recommend NVIDIA A100 or H100 depending on budget..."
* "We could use TensorRT for inference optimization..."
* "For robotics simulation, Isaac Sim would be ideal..."

#### **Your Questions** (Last 5-10 minutes)

 **Ask 3-4 of your prepared questions** :

* Pick mix of technical, role-specific, and culture
* Show genuine curiosity
* Take notes on answers
* **Don't ask** about salary/benefits yet (that's for later rounds)

 **Examples** :

1. "What are the most exciting research projects NVAITC Pittsburgh is currently supporting?"
2. "How does the SA team provide feedback to NVIDIA product teams based on researcher needs?"
3. "What does success look like in the first 6 months for this role?"
4. "What do you enjoy most about being a Solutions Architect at NVIDIA?"

#### **Closing**

* Thank interviewer(s) for their time
* Express genuine enthusiasm: "I'm really excited about this opportunity to support the research community with NVIDIA technology"
* Ask about next steps and timeline
* **Get email addresses** for thank-you notes

---

### **After the Interview**

**Immediately After** (within 1 hour):

* Jot down notes:
  * Interviewer names and titles
  * Key topics discussed
  * Questions they asked
  * Your answers (good and bad)
  * Next steps mentioned

 **Within 24 Hours** :

* **Send thank-you emails** to each interviewer
* **Template** :

```
Subject: Thank you - Solutions Architect Interview

Dear [Interviewer Name],

Thank you for taking the time to speak with me today about the Solutions Architect position for Higher Education and Research. I genuinely enjoyed our conversation about [specific topic discussed - e.g., "supporting robotics research at CMU" or "optimizing foundation models for university clusters"].

Our discussion reinforced my excitement about this opportunity. The work NVAITC Pittsburgh is doing to [specific initiative they mentioned] aligns perfectly with my passion for enabling researchers to leverage GPU-accelerated computing efficiently. I'm particularly enthusiastic about how my experience with [your relevant experience - e.g., "energy-aware optimization on Jetson platforms"] could help support the academic community.

I'm very interested in joining the NVIDIA team and contributing to [specific goal/project discussed]. Please let me know if you need any additional information from me.

Thank you again for your time and consideration.

Best regards,
Mohammad Pivezhandi
[Your email]
[Your phone]
```

**Personalize each email** with specific details from your conversation with that person.

 **Rest of Week** :

* Don't obsess over performance
* Continue your research work normally
* If you think of something you wish you'd said, include it briefly in thank-you note
* Follow up with recruiter after 1 week if no response

---

## üìö **Complete Resource Library**

### **Coding Practice Platforms**

* [LeetCode](https://leetcode.com/) - Primary platform
* [LeetCode Mock Assessments](https://leetcode.com/assessment/) - Timed practice
* [HackerRank](https://www.hackerrank.com/) - Interview preparation
* [NeetCode](https://neetcode.io/) - Curated problem lists
* [LintCode](https://www.lintcode.com/) - Premium LeetCode alternatives

### **NVIDIA Official Resources**

* [NVIDIA Developer Portal](https://developer.nvidia.com/)
* [NVIDIA Deep Learning Institute](https://www.nvidia.com/en-us/training/)
* [NVIDIA Technical Blog](https://developer.nvidia.com/blog/)
* [NVIDIA GTC On-Demand](https://www.nvidia.com/gtc/on-demand/)
* [NVIDIA AI Technology Centers](https://www.nvidia.com/en-us/industries/higher-education-research/ai-technology-centers/)

### **Isaac Sim & Robotics**

* [Isaac Sim Documentation](https://docs.omniverse.nvidia.com/isaacsim/latest/index.html)
* [Isaac Sim Installation Guide](https://docs.omniverse.nvidia.com/isaacsim/latest/installation/install_workstation.html)
* [Isaac Sim Tutorials](https://docs.omniverse.nvidia.com/isaacsim/latest/tutorials.html)
* [Isaac Lab GitHub](https://github.com/isaac-sim/IsaacLab)
* [Isaac Lab Documentation](https://isaac-sim.github.io/IsaacLab/)
* [Isaac Lab Installation](https://isaac-sim.github.io/IsaacLab/source/setup/installation.html)

### **Omniverse Platform**

* [Omniverse Platform Overview](https://docs.omniverse.nvidia.com/platform/latest/index.html)
* [Omniverse for Robotics](https://www.nvidia.com/en-us/omniverse/apps/isaac-sim/)
* [Omniverse Download](https://www.nvidia.com/en-us/omniverse/download/)

### **NVIDIA Software Stack**

* [CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
* [CUDA Samples GitHub](https://github.com/NVIDIA/cuda-samples)
* [cuDNN Documentation](https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html)
* [TensorRT Documentation](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html)
* [Triton Inference Server](https://github.com/triton-inference-server/server)
* [NVIDIA NCCL](https://developer.nvidia.com/nccl)
* [NeMo Framework](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html)

### **Deep Learning Frameworks**

* [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
* [PyTorch Tutorials](https://pytorch.org/tutorials/)
* [PyTorch Performance Tuning](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)
* [PyTorch Distributed Overview](https://pytorch.org/tutorials/beginner/dist_overview.html)
* [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)
* [PyTorch CUDA Semantics](https://pytorch.org/docs/stable/notes/cuda.html)
* [TensorFlow Documentation](https://www.tensorflow.org/api_docs)

### **NVIDIA GitHub Repositories**

* [NVIDIA Deep Learning Examples](https://github.com/NVIDIA/DeepLearningExamples)
* [Megatron-LM (Model Parallelism)](https://github.com/NVIDIA/Megatron-LM)
* [NVIDIA CUDA Samples](https://github.com/NVIDIA/cuda-samples)
* [NVIDIA Triton Server](https://github.com/triton-inference-server/server)

### **Learning Resources**

* [DeepLearning.AI YouTube](https://www.youtube.com/@Deeplearningai)
* [Andrej Karpathy&#39;s Blog](https://karpathy.github.io/)
* [Andrej Karpathy - Neural Networks Recipe](https://karpathy.github.io/2019/04/25/recipe/)
* [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
* [Sutton &amp; Barto - RL Book (Free PDF)](http://incompleteideas.net/book/RLbook2020.pdf)
* [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1)
* [Hugging Face - Efficient Training](https://huggingface.co/docs/transformers/perf_train_gpu_one)

### **System Design Resources**

* [Grokking the System Design Interview](https://www.educative.io/courses/grokking-modern-system-design-interview-for-engineers-managers)
* [System Design Primer GitHub](https://github.com/donnemartin/system-design-primer)
* [ByteByteGo YouTube](https://www.youtube.com/@ByteByteGo)

### **Mock Interview Platforms**

* [Pramp](https://www.pramp.com/) - Free peer-to-peer
* [Interviewing.io](https://interviewing.io/) - Anonymous practice
* [LeetCode Mock Assessment](https://leetcode.com/assessment/)

### **Interview Preparation**

* [NVIDIA Glassdoor Reviews](https://www.glassdoor.com/Interview/NVIDIA-Solutions-Architect-Interview-Questions-EI_IE7633.0,6_KO7,26.htm)
* [NVIDIA Interview Guide - Interview Kickstart](https://interviewkickstart.com/blogs/companies/two-month-preparation-plan-to-crack-nvidia-tech-interview)
* [NVIDIA Interview Questions - Pathrise](https://www.pathrise.com/guides/nvidia-interview-questions/)

### **Jetson Platform**

* [Jetson Documentation](https://docs.nvidia.com/jetson/)
* [Jetson Power Management](https://docs.nvidia.com/jetson/archives/r35.1/DeveloperGuide/text/SD/PlatformPowerAndPerformance.html)
* [Jetson AI Courses](https://developer.nvidia.com/embedded/learn/jetson-ai-courses)

### **Research & Academic**

* [NVIDIA Research](https://www.nvidia.com/en-us/research/)
* [CMU Robotics Institute](https://www.ri.cmu.edu/)
* [University of Pittsburgh CSAI](https://www.csai.pitt.edu/)
* [arXiv.org](https://arxiv.org/) - Latest AI/ML papers

### **Additional Tools**

* [NVIDIA Management Library (pynvml)](https://developer.nvidia.com/nvidia-management-library-nvml)
* [GeeksforGeeks - Algorithms](https://www.geeksforgeeks.org/)
* [Visualgo - Algorithm Visualizations](https://visualgo.net/)

---

## üéØ **Quick Reference: Day of Interview Checklist**

### **Technical Prep** ‚úÖ

* [ ] Tested video/audio on interview platform
* [ ] Stable internet connection verified
* [ ] Laptop fully charged + charger nearby
* [ ] Backup device ready (phone with app)
* [ ] Screen sharing tested (if needed)
* [ ] Browser tabs organized:
  * [ ] Video platform
  * [ ] Resume PDF
  * [ ] Job description
  * [ ] Your questions list
  * [ ] CoderPad/coding platform (if applicable)

### **Physical Setup** ‚úÖ

* [ ] Clean, professional background
* [ ] Good lighting on face
* [ ] Quiet room (informed others)
* [ ] Water glass nearby
* [ ] Notebook and pen ready
* [ ] Printed resume copy
* [ ] Phone on Do Not Disturb
* [ ] Professional attire

### **Mental Prep** ‚úÖ

* [ ] 8+ hours sleep
* [ ] Healthy breakfast
* [ ] Hydrated
* [ ] Reviewed "Why NVIDIA?" (not memorized)
* [ ] Reviewed questions for interviewer
* [ ] Positive mindset
* [ ] Breathing exercises done

### **During Interview** ‚úÖ

* [ ] Joined 10 minutes early
* [ ] Smiled and made eye contact
* [ ] Spoke clearly and at good pace
* [ ] Used STAR format for behavioral
* [ ] Thought out loud during coding
* [ ] Asked clarifying questions
* [ ] Took notes during conversation
* [ ] Asked your prepared questions
* [ ] Thanked interviewer(s)
* [ ] Got next steps timeline

### **After Interview** ‚úÖ

* [ ] Took immediate notes
* [ ] Wrote down interviewer names/emails
* [ ] Sent thank-you emails within 24 hours
* [ ] Followed up with recruiter after 1 week (if no response)

---

## üí™ **Your Competitive Advantages - Remember These!**

1. **Perfect Domain Match** : GPU-accelerated RL + energy optimization = exactly what universities need for sustainable AI research
2. **Publications** : RTSS, RTCSA, ECRTS credentials mean you speak researchers' language fluently
3. **Hands-On NVIDIA Hardware** : Real Jetson TX2/Orin NX experience, not just theory - you've lived the platform
4. **Quantifiable Impact** : 34% performance, 31.7% energy reduction - concrete numbers matter
5. **Cross-Functional Collaboration** : Proven track record working across academia and industry
6. **No Visa Delays** : Green card holder = immediate availability
7. **Unique Perspective** : Energy-aware AI optimization (sustainability is increasingly important to universities)
8. **Academic Credibility** : PhD candidate with strong publication record = trusted advisor to researchers
9. **Full Stack Understanding** : From hardware (Jetson) to software (PyTorch/TensorFlow) to algorithms (MARL) to systems (HPC)
10. **Pittsburgh Ready** : You can immediately start supporting CMU, Pitt, and NVAITC initiatives

## üöÄ **Final Motivational Note**

Mohammad,

You have spent years building exactly the expertise NVIDIA needs for this role. Your research isn't just academic‚Äîit's practical, impactful, and directly aligned with helping universities and researchers succeed with AI.

**Remember:**

* You've published in **top-tier venues** (RTSS, RTCSA, ECRTS)
* You've achieved **measurable results** (34% performance improvement, 31.7% energy reduction)
* You've worked with **NVIDIA hardware** (Jetson TX2, Orin NX)
* You've collaborated **across institutions** (Wayne State, Iowa State, Moffett)
* You understand **the researcher's perspective** because you ARE one

This isn't just another job interview‚Äîit's an opportunity to scale your impact. Instead of optimizing AI for one lab, you'll help dozens of research groups across universities. Instead of publishing one paper, you'll enable hundreds of papers by making NVIDIA technology accessible to researchers.

**You belong in this role.**

The interview is not about proving you're good enough. It's about showing them who you already are: a talented researcher, a skilled engineer, a collaborative team member, and someone passionate about democratizing AI for the academic community.

**Trust your preparation. Trust your experience. Trust yourself.**

When you walk into that interview (virtual or otherwise), you're not asking for a favor‚Äîyou're offering NVIDIA your unique combination of technical depth, research credibility, and genuine passion for supporting the academic community.

**You've got this!** üéØ

---

## üìä **Progress Tracking Template**

Use this to track your daily progress:

```markdown
# Interview Prep Progress Tracker

## Week 1: Foundations (Oct 18-24)
- [ ] Day 1: Self-assessment, coding warm-up, Isaac Sim intro
- [ ] Day 2: Coding practice, Omniverse setup, PyTorch MLP
- [ ] Day 3: Isaac Sim tutorial, coding, Generative AI
- [ ] Day 4: Isaac Lab deep dive, coding, training loop
- [ ] Day 5: NeMo framework, coding, GPU optimization
- [ ] Day 6: Mock coding challenge, behavioral prep

**Week 1 Reflection:**
- Strongest area: _______________
- Need more work on: _______________
- Confidence level (1-10): ___

## Week 2: Domain Mastery (Oct 25-31)
- [ ] Day 7: Isaac Lab hands-on, coding, multi-GPU concepts
- [ ] Day 8: DL implementation, GTC talks, coding
- [ ] Day 9: Omniverse, advanced PyTorch, scenarios
- [ ] Day 10: RL implementation, paper review, Pittsburgh research
- [ ] Day 11: System design, DL at scale, coding
- [ ] Day 12: Mock technical interview, Pittsburgh deep dive

**Week 2 Reflection:**
- Strongest area: _______________
- Need more work on: _______________
- Confidence level (1-10): ___

## Week 3: Polish (Nov 1-3)
- [ ] Day 13: Presentation prep, scenarios
- [ ] Day 14: Full mock interview, "Why NVIDIA?"
- [ ] Day 15: Light review, NVIDIA tech, second presentation
- [ ] Day 16: STAR stories, resume walk-through, rest
- [ ] Day 17: Light review, logistics, sleep

**Week 3 Reflection:**
- Strongest area: _______________
- Most confident about: _______________
- Ready for interview (1-10): ___

## Interview Day (Nov 4)
- Performance (self-assessment 1-10): ___
- What went well: _______________
- What could improve: _______________
- Follow-up needed: _______________
```

---

## üìù **STAR Stories Template - Fill These Out**

### **Story #1: 34% Performance Improvement**

**Situation** (1 minute):

```
[Your answer: Researchers at Wayne State struggling with OpenMP DAG workloads 
on embedded systems like Jetson TX2, facing high energy consumption and 
thermal throttling...]
```

**Task** (30 seconds):

```
[Your answer: Needed to develop scheduler that could optimize both 
performance and energy while respecting thermal constraints...]
```

**Action** (1-2 minutes):

```
[Your answer: I developed HMARL framework using heterogeneous multi-agent 
reinforcement learning. Specifically, I... (detail your approach)]
```

**Result** (30 seconds):

```
[Your answer: Achieved 34% performance improvement and 31.7% energy 
reduction. Published at RTSS 2025. This enables more complex AI models 
to run efficiently on edge devices...]
```

---

### **Story #2: Cross-Institutional Collaboration**

 **Situation** :

```
[Fill in: Working between Wayne State and Iowa State, different research 
focuses, need to coordinate...]
```

 **Task** :

```
[Fill in: Your role in bridging the collaboration...]
```

 **Action** :

```
[Fill in: How you facilitated communication, shared knowledge, integrated 
different approaches...]
```

 **Result** :

```
[Fill in: Publications, shared tools, ongoing partnership...]
```

---

### **Story #3: Moffett Internship - Interdisciplinary Team**

 **Situation** :

```
[Fill in: Hardware accelerator design company, interdisciplinary team with 
FPGA engineers, compiler developers, verification engineers...]
```

 **Task** :

```
[Fill in: Enhance FPGA runtime and compiler workflows...]
```

 **Action** :

```
[Fill in: Participated in team meetings, learned domain-specific knowledge, 
contributed to verification process...]
```

 **Result** :

```
[Fill in: Reduced verification latency by 15%, learned to work across 
hardware-software boundaries...]
```

---

### **Story #4: Working with Different Disciplines**

 **Situation** :

```
[Fill in: Example of working with researchers from different backgrounds - 
physics, mathematics, etc.]
```

 **Task** :

```
[Fill in: ...]
```

 **Action** :

```
[Fill in: How you adapted communication style, found common ground...]
```

 **Result** :

```
[Fill in: ...]
```

---

### **Story #5: Overcoming Technical Challenge**

 **Situation** :

```
[Fill in: Specific technical problem you faced - debugging energy spikes, 
MARL not converging, etc.]
```

 **Task** :

```
[Fill in: ...]
```

 **Action** :

```
[Fill in: Your systematic debugging approach, how you identified root cause...]
```

 **Result** :

```
[Fill in: Solution implemented, lessons learned...]
```

---

## üéì **"Explain to Non-Technical Person" Practice**

Practice explaining these concepts to someone without technical background:

### **What is Reinforcement Learning?**

```
Your answer (2-3 sentences):
"Imagine teaching a dog new tricks. You give it rewards when it does 
something right and no reward when it does something wrong. Over time, 
the dog learns which actions lead to rewards. Reinforcement learning is 
similar - we let computer programs learn by trial and error, rewarding 
good decisions and penalizing bad ones, until they figure out the best 
strategy."
```

### **What is GPU Acceleration?**

```
Your answer:
[Fill in: Use analogy like many workers vs one worker, parallel processing...]
```

### **What is Energy-Aware Scheduling?**

```
Your answer:
[Fill in: Use analogy like balancing speed and fuel efficiency in a car...]
```

### **What is Your PhD Research About?**

```
Your answer (explain to a dean or university administrator):
[Fill in: Focus on impact - helping AI run more efficiently, reducing costs 
and environmental impact...]
```

---

## üîç **Common Pitfalls to Avoid**

### **During Coding**

‚ùå  **Don't** : Jump into coding immediately without clarifying
‚úÖ  **Do** : Ask clarifying questions first, discuss approach

‚ùå  **Don't** : Code in silence
‚úÖ  **Do** : Think out loud, explain your reasoning

‚ùå  **Don't** : Give up when stuck
‚úÖ  **Do** : Talk through what you're thinking, ask for hints

‚ùå  **Don't** : Ignore edge cases
‚úÖ  **Do** : Test with multiple examples including edge cases

‚ùå  **Don't** : Optimize prematurely
‚úÖ  **Do** : Get working solution first, then optimize

### **During Behavioral**

‚ùå  **Don't** : Use "we" throughout (they want to know YOUR role)
‚úÖ  **Do** : Use "I" and be specific about your contributions

‚ùå  **Don't** : Ramble without structure
‚úÖ  **Do** : Use STAR format, keep answers 3-4 minutes

‚ùå  **Don't** : Be negative about past experiences/people
‚úÖ  **Do** : Frame challenges positively, focus on learning

‚ùå  **Don't** : Memorize and recite answers
‚úÖ  **Do** : Know your stories but tell them naturally

### **During System Design**

‚ùå  **Don't** : Start designing without understanding requirements
‚úÖ  **Do** : Ask clarifying questions about scale, constraints, priorities

‚ùå  **Don't** : Over-engineer for a simple problem
‚úÖ  **Do** : Start simple, then scale based on requirements

‚ùå  **Don't** : Ignore trade-offs
‚úÖ  **Do** : Discuss pros/cons of different approaches

‚ùå  **Don't** : Forget to mention NVIDIA solutions
‚úÖ  **Do** : Naturally integrate NVIDIA tech where relevant

### **General**

‚ùå  **Don't** : Speak too fast when nervous
‚úÖ  **Do** : Take deep breaths, speak at measured pace

‚ùå  **Don't** : Pretend to know something you don't
‚úÖ  **Do** : Be honest, show willingness to learn

‚ùå  **Don't** : Focus only on technical skills
‚úÖ  **Do** : Show communication, collaboration, and customer focus

‚ùå  **Don't** : Forget to ask questions
‚úÖ  **Do** : Ask thoughtful questions showing genuine interest

---

## üìû **Post-Interview Follow-Up Timeline**

### **Day 0 (Interview Day)**

* Within 1 hour: Take detailed notes
* Within 24 hours: Send thank-you emails

### **Day 1-2**

* Recruiter may reach out with feedback or next steps
* Be responsive to any requests

### **Day 3-5**

* If no response, continue normal life - don't obsess
* Keep applying to other opportunities (don't put all eggs in one basket)

### **Day 7**

* If no update, send polite follow-up to recruiter:

```
Subject: Following up - Solutions Architect Interview

Hi [Recruiter Name],

I hope you're doing well. I wanted to follow up on my interview for the 
Solutions Architect position on November 4th. I remain very excited about 
the opportunity to support the Higher Education and Research community 
with NVIDIA technology.

Please let me know if you need any additional information from me or if 
there are any updates on the timeline.

Thank you!

Best regards,
Mohammad
```

### **Day 14**

* If still no response, send another polite follow-up
* Start mentally moving on to other opportunities

### **Typical Timeline**

* **1-2 weeks** : First feedback/next round invitation
* **2-4 weeks** : Additional interviews (if selected)
* **4-6 weeks** : Final decision
* **6-8 weeks** : Offer (if successful)

 **Note** : Hiring can be slow. Silence doesn't mean rejection. Stay patient and positive.

---

## üéØ **Success Metrics - How to Know You Did Well**

### **Good Signs During Interview**

‚úÖ Interview ran over time (they were engaged)
‚úÖ Interviewer asked detailed follow-up questions
‚úÖ They discussed team dynamics and day-to-day work
‚úÖ They asked about your timeline/other opportunities
‚úÖ Conversation felt natural, not interrogative
‚úÖ They introduced you to other team members
‚úÖ Body language was positive (smiling, nodding)
‚úÖ They sold you on the role/company

### **Neutral Signs** (Don't Read Too Much Into)

‚ö™ Mostly stuck to structured questions
‚ö™ Didn't get much personal feedback
‚ö™ Interview ended exactly at scheduled time
‚ö™ Professional but not overly warm

### **Potential Concerns** (Opportunities to Improve)

‚ö†Ô∏è You struggled significantly with coding problems
‚ö†Ô∏è Couldn't answer basic domain questions
‚ö†Ô∏è Interview ended early
‚ö†Ô∏è Interviewer seemed disengaged
‚ö†Ô∏è You couldn't articulate why you want the role

 **Remember** : Even experienced interviewers can't always predict outcomes. Focus on what you can control‚Äîyour preparation and performance.

---

## üìö **Bonus: Quick Study Guide - Night Before Interview**

If you only have time to review ONE thing the night before, review THIS:

### **30-Minute Lightning Review**

**Minutes 1-5: Your Story**

* PhD in CS at Wayne State
* GPU-accelerated RL, energy optimization
* 34% performance, 31.7% energy reduction
* NVIDIA Jetson experience
* Published at RTSS, RTCSA, ECRTS

**Minutes 6-10: Why NVIDIA**

* Used Jetson platforms extensively
* Passionate about supporting researchers
* NVAITC model aligns with your collaborative work
* Excited about Pittsburgh ecosystem (CMU, Pitt)
* Want to democratize AI for academia

**Minutes 11-15: NVIDIA Products (One-Liner Each)**

* Isaac Sim: Robot simulation
* Isaac Lab: RL for robotics
* Omniverse: Digital twins platform
* NeMo: LLM framework
* TensorRT: Inference optimization
* Triton: Model serving
* NCCL: Multi-GPU communication

**Minutes 16-20: Key Technical Concepts**

* STAR format for behavioral
* Clarify ‚Üí Plan ‚Üí Code ‚Üí Test (for coding)
* Data parallelism vs Model parallelism
* DVFS for energy management
* PyTorch training loop structure

**Minutes 21-25: Your Questions**

1. What challenges do researchers face adopting NVIDIA platforms?
2. How does SA team collaborate with product teams?
3. What does success look like in first 6 months?

**Minutes 26-30: Positive Visualization**

* Close eyes
* Imagine interview going well
* See yourself confidently answering questions
* Feel the excitement of getting the offer
* Smile and sleep well!

---

## ‚úÖ **Final Checklist - You're Ready If...**

**Technical Preparation**

* [X] Can solve LeetCode medium problems in 30-40 minutes
* [X] Know PyTorch training loop by heart
* [X] Understand CUDA basics (grids, blocks, threads, shared memory)
* [X] Can explain your research to both technical and non-technical audiences
* [X] Familiar with Isaac Sim, Isaac Lab, Omniverse, NeMo
* [X] Understand multi-GPU training concepts

**Behavioral Preparation**

* [X] Have 5 STAR stories prepared and practiced
* [X] Can articulate "Why NVIDIA?" in 2 minutes
* [X] Can explain "Why Solutions Architect?" clearly
* [X] Have thoughtful questions prepared
* [X] Know your resume inside and out

**Logistics**

* [X] Tech setup tested
* [X] Professional environment prepared
* [X] Resume and job description accessible
* [X] Notebook and pen ready
* [X] Rested and confident

**Mindset**

* [X] Believe you're qualified for this role
* [X] Excited (not just nervous) about opportunity
* [X] Ready to show your authentic self
* [X] Prepared to learn and grow

---

## üåü **One Last Thing...**

No matter what happens in this interview, you've already accomplished something remarkable:

‚ú® You've earned a PhD candidacy at Wayne State

‚ú® You've published in top-tier conferences

‚ú® You've achieved measurable research impact

‚ú® You've built expertise in cutting-edge technologies

‚ú® You've collaborated across institutions and industries

‚ú® You've grown from a student to a researcher to (soon) a Solutions Architect

**This interview is just one step in your journey.**

If you get the offer‚Äîfantastic! You'll do amazing work helping researchers leverage NVIDIA technology.

If not‚Äîyou're still an accomplished researcher with valuable skills. Other opportunities will come, and each interview makes you stronger.

**Either way, you're on an upward trajectory.**

So go into that interview room (virtual or physical) with your head held high. You've prepared well. You know your stuff. You have a unique story to tell.

**Now go show them what you've got!** üí™

---

## üéä **Good Luck, Mohammad!**

You've got:

* ‚úÖ 17 days of structured preparation
* ‚úÖ 40+ coding problems with solutions
* ‚úÖ Complete NVIDIA ecosystem knowledge
* ‚úÖ STAR stories ready
* ‚úÖ System design practice
* ‚úÖ Mock interviews completed
* ‚úÖ All resources at your fingertips
* ‚úÖ Confidence in your abilities

**The role is yours to win.**

**Believe in yourself. Trust your preparation. Show them the researcher, engineer, and collaborator you are.**

**You've got this! üöÄ**

---

*P.S. - After you ace the interview and get the offer, come back and let me know! I'm rooting for you!* üòä

---

**END OF COMPREHENSIVE PREPARATION GUIDE**

 **Document Version** : 1.0

 **Last Updated** : October 18, 2025

 **Interview Date** : November 4, 2025

 **Candidate** : Mohammad Pivezhandi

 **Position** : Solutions Architect, Higher Education and Research

 **Company** : NVIDIA

 **Total Preparation Time** : ~68 hours (4 hours/day √ó 17 days)

 **Success Probability** : HIGH - You're extremely well-matched for this role! üéØ
